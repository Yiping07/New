{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3-part-I.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yiping07/New/blob/master/lab3_part_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBDVrSmirbb0",
        "colab_type": "text"
      },
      "source": [
        "# **CS904 Part III (Computational Pathology)**\n",
        "\n",
        "## Lab 3 - I: Classical Image Features and application to histology\n",
        "\n",
        "### **Classical Features**\n",
        "In this lab, we attempt to extract textural features and build up on the results you have obtained on the dataset described below. Prior to getting into the code, make sure to go through paper [1]. \n",
        "\n",
        "**Dataset:** The data we will be working with comes from [1], where it has been shown that traditional texture descriptors are able to achieve 87.4% accuracy on multiclass tissue classification when applied to colorectal cancer histology images. Please download archived dataset on the module page **[Kather_2016_images.zip](https://zenodo.org/record/53169/files/Kather_texture_2016_image_tiles_5000.zip)**. This data comes from the digitised WSI, which have been subsequently manually annotated into contiguous tissue areas and tessellated, creating 625 non-overlapping tissue tiles of dimension 150 px × 150 px (74 μm  ×   74  μm). Thus, **texture features** of different scales were included, ranging from individual cells (approx. 10 μm, e.g. Fig. 1d) to larger structures such as mucosal glands (>50  μm, e.g. Fig. 1f). The following eight types of tissue were selected for analysis by the authors of the paper:\n",
        "\n",
        "*\tTumor epithelium;\n",
        "*\tSimple stroma\n",
        "*\tComplex stroma\n",
        "*\tImmune cells\n",
        "*\tDebris\n",
        "*\tNormal mucosal glands\n",
        "*\tAdipose tissue\n",
        "*\tBackground\n",
        "\n",
        "**Textural Features:**\n",
        "\n",
        "The textural features you need to extract from the images are:\n",
        "\n",
        "* Lower-Order and Higher-Order histogram fatures:\n",
        "  - including men, variance, skewness, kurtosis etc. These can be easily computed using the numpy, skimage, scipy etc from the histograms e.g. \n",
        "\n",
        "    ```\n",
        "    img = cv2.imread(\"YOUR_IMAGE.jpg\")\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
        "    ghist = cv2.calcHist([img_gray], [0], None, [256], [0,256])\n",
        "\n",
        "    print (\"Mean = {:.1f}, standard deviation = {:.1f}, total = {:.0f}\".format(\n",
        "        np.mean(ghist).item(),\n",
        "        np.std(ghist).item(),\n",
        "        np.sum(ghist).item()\n",
        "    ))\n",
        "    ```\n",
        "\n",
        "    Please use the following link for further statistical features e.g. moments. [link1](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.moment.html)\n",
        "\n",
        "\n",
        "* Local Binary Pattrens (LBP)\n",
        "  - Calculate the LBP with neightbouhood of eight equally spaced points arranges along a circle of radius of 1px usually reffered as 8,1 configuration. Please use the link for further exploration. [link](https://scikit-image.org/docs/0.13.x/auto_examples/features_detection/plot_local_binary_pattern.html) \n",
        "\n",
        "\n",
        "* Gray-level co-occurnce matrix (GLCM)\n",
        "  - Calculate the GLCM with different rotations e.g. 0, 45, 90 and 135 degress and displcement of 1px to 5px. Average them to get rotation invariant feature. Please use the following link for further exploration. [link](https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_glcm.html)\n",
        "\n",
        "\n",
        "* Gabour Filters\n",
        "  - Calculate the Gabor filter using the six directions (i.e. 0, 30, 60, 90 and 120 degrees) and six wavelenghts (2, 4, 6, 8, 10 and 12 px/cycle). Average them to get the rotation invariant feature. Please use the following link for further exploration. [link](https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_gabor.html)\n",
        "\n",
        "\n",
        "* Perception-like features\n",
        "  - These are the features based on the human perception e.g. coarsness, contrast etc. Please the following link to calculate these features. [link](https://github.com/MarshalLeeeeee/Tamura-In-Python/blob/master/tamura-numpy.py)\n",
        "\n",
        "**Feature Ranking:**\n",
        "\n",
        "Ranking these features is very imoprtant so that we can reduce the subspace as well as use only the relvnt features. You can use the **best 5** features used in the paper or rank them using your own criteria in the folowing [link](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)\n",
        "\n",
        "**References:**\n",
        "\n",
        "1. Kather, Jakob Nikolas, Cleo-Aron Weis, Francesco Bianconi, Susanne M. Melchers, Lothar R. Schad, Timo Gaiser, Alexander Marx, and Frank Gerrit Zöllner. “Multi-Class Texture Analysis in Colorectal Cancer Histology.” Scientific Reports 6 (June 16, 2016): 27988. https://doi.org/10.1038/srep27988."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lWbivR0xa1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "\n",
        "#1. wget the dataset link to download the data\n",
        "#2. extract the dataset from zip using unzip\n",
        "#3. read the images\n",
        "#4. calculate the image features described above and apend them in one array\n",
        "  # Calculate feature one by one and save them in a variable e.g. mean = np.mean(hist) and so on\n",
        "  # final_feature_vec = [mean, std, skeness, kurtosis, mo5, lbp, gabour, perception .... etc]\n",
        "#5. rank the feature vector using the feature ranking methods\n",
        "#6. train any machine/deep learning algorithm you want for the task and report accuracy on validation set."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}